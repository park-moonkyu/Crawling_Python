{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 웹 크롤링 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나의 경우 엑셀에서 추출한 제품명의 최저가를 웹에서 추출하기 위해 크롤링을 구현\n",
    "따라서 아래 코드는 엑셀에서 원하는 컬럼을 가져온다. 엑셀에서 원하는 컬럼을 추출하는 예제는 아래 링크를 참고하기 바란다 <br>\n",
    "https://github.com/park-moonkyu/oepnpyxl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NT930QCG-K58A', '박문규', '20.11.03']\n",
      "['NT350XCR-AD5WA', '임선정', '20.11.05']\n",
      "['15ZD90N-VX50K', '권규현', '20.10.29']\n",
      "['15UD40N-GX36K', '이승호', '20.10.29']\n",
      "['15UD40N-GX36K', '박문규', '20.10.28']\n",
      "['75ATD430N-66h', '김민창', '20.10.29']\n",
      "['NT350XCR-AD5WA', '박문규', '20.10.29']\n",
      "['NT950XCR-G58A', '박문규', '20.10.29']\n",
      "['17ZD90N-VX70K', '권규현', '20.10.29']\n",
      "['NT950QCT-A58A', '권규현', '20.10.29']\n",
      "['15ZD90N-HX56K', '임선정', '20.10.29']\n",
      "['17ZD90N-VX50K', '박문규', '20.10.29']\n",
      "['NT950XCR-A58A', '임선정', '20.10.29']\n",
      "['NT950XCJ-X716A', '권규현', '20.10.29']\n",
      "[None, None, None]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import openpyxl\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 엑셀파일 열기\n",
    "filename = \"test.xlsx\"\n",
    "book = openpyxl.load_workbook(filename)\n",
    "\n",
    "# 맨 앞의 시트 추출하기\n",
    "sheet = book.worksheets[0]\n",
    "\n",
    "# 시트의 각 행을 순서대로 추출하기\n",
    "data = []\n",
    "for row in sheet.rows:\n",
    "    data.append([row[0].value, row[1].value,row[2].value])\n",
    "\n",
    "del data[0]\n",
    "\n",
    "for i in range(len(data)):\n",
    "    print(data[i])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다양한 크롤링 라이브러리\n",
    "\n",
    "파이썬으로 웹을 크롤링할수있는 라이브러리와 프레임워크는 매우 다양하다. <br>\n",
    "그중 BeautifulSoap 와 Selenium 을 활용해보고자 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requests or urlib(beautifulsoup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beautifulsoap는 HTML, XML 파일의 정보를 추출해내는 python 라이브러리 이다. <br><br>\n",
    "이 방식은 python 내장 모듈인 requests 혹은 urllib 을 이용해 HTML을 다운받고, beautifulsoup로 데이터를 추출하는 방식이다.<br>\n",
    "해당 방식은 HTML을 다운 받기에 , 서버사이드렌더링을 사용하지않는 SPA 사이트나, javaScript 렌더링을 필요로하는 사이트들은 크롤링하기 어렵다고 한다.<br><br><br>\n",
    "SPA 에 대한 설명 : https://m.blog.naver.com/PostView.nhn?blogId=azure0777&logNo=220812404024&proxyReferer=https:%2F%2Fwww.google.com%2F<br>\n",
    "렌더링에 대한 설명 : https://tuhbm.github.io/2017/08/10/rendering1/<br><br>\n",
    "장점 --> 쉽고 멀티프로세스 혹은 멀티 쓰레드 적용시엔 빠르다. <br>\n",
    "단점 --> 렌더링이 필요한 사이트들을 크롤링하기 어려움. 병렬처리 로직을 별도로 작성하지 않으면 느린편 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "셀리니움은 웹 자동화 테스트(버튼클릭, 스크롤 조작)에 사용되는 프레임워크이다.<br>\n",
    "셀리니움을 이용한 크롤러는 웹 페이지에서 javascript 렌더링을 통해 생성되는 데이터들을 손쉽게 가져올수있다.<br>\n",
    "인터넷브라우저를 통해 크롤링을 하는 개념이라, 실제 보여지는 웹페이지의 전부를 가져올 수 있고 디버깅 방법 또한 직관적이다.<br>\n",
    "하지만 실제 웹브라우저를 실행시키는 방법이기때문에 속도가 많이 느리고 메모리도 상대적으로 많이 차지한다.<br>\n",
    "멀티프로세스를 사용해서 여러 브라우저를 크롤링하도록 하면 속도를 개선할수있다.<br>\n",
    "셀리니움 사용시 도커를 사용하면 편리하다고한다. (아직 도커를 이용해서 크롤링을 해보진않았다 ㅠㅠ) <br><br><br>\n",
    "장점 --> 사용바작 보는 웹 페이지의 모든 정보를 가져올 수 있다.<br>\n",
    "단점 --> 느리고 메모리를 많이 차지한다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
